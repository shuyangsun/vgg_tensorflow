{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_graph(train_loss, dev_loss, use_log=True):\n",
    "    if use_log:\n",
    "        train_loss = np.log(train_loss)\n",
    "        dev_loss = np.log(dev_loss)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    train_line, = plt.plot(train_loss, label='train')\n",
    "    dev_line, = plt.plot(dev_loss, label='dev')\n",
    "    plt.legend(handles=[train_line, dev_line])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define VGG-16 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16:\n",
    "    def __init__(self, img_size, num_categories, learning_rate, momentum=0.9, filter_size=(3, 3)):\n",
    "        self._tf_graph = tf.Graph()\n",
    "        self._saved_model_path = os.path.join(tempfile.mkdtemp(), 'model.ckpt')\n",
    "        self._tf_dict = self._get_tf_dict(self._tf_graph, img_size, num_categories, learning_rate, momentum)\n",
    "        self._train_loss = []\n",
    "        self._dev_loss = []\n",
    "\n",
    "    def train(self, dataset, batch_size, num_epoch, loss_interval=10):\n",
    "        print('Started training...')\n",
    "        \n",
    "        self._train_loss = []\n",
    "        self._dev_loss = []\n",
    "        \n",
    "        start = time.time()\n",
    "        sample_count = 0\n",
    "        with self._tf_graph.as_default():\n",
    "            with tf.Session(graph=self._tf_graph) as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                last_epoch = 0\n",
    "                while last_epoch < num_epoch:\n",
    "                    batch = dataset.train.next_batch(batch_size)\n",
    "                    feed_dict = {\n",
    "                        self._tf_dict['X']: batch[0],\n",
    "                        self._tf_dict['Y']: batch[1]\n",
    "                    }\n",
    "                    sess.run(self._tf_dict['optimizer'], feed_dict=feed_dict)\n",
    "                    sample_count += batch[0].shape[0]\n",
    "                    epoch = sample_count // batch_size\n",
    "                    if epoch > last_epoch:\n",
    "                        last_epoch = epoch\n",
    "                        if epoch % loss_interval == 0:\n",
    "                            self._train_loss.append(sess.run(self._tf_dict['cost'], feed_dict={\n",
    "                                self._tf_dict['X']: batch[0],\n",
    "                                self._tf_dict['Y']: batch[1]\n",
    "                            }))\n",
    "                            self._dev_loss.append(sess.run(self._tf_dict['cost'], feed_dict={\n",
    "                                self._tf_dict['X']: dataset.test.images,\n",
    "                                self._tf_dict['Y']: dataset.test.labels\n",
    "                            }))\n",
    "                    if (epoch + 1) % 100 == 0:\n",
    "                        print('Finished epoch {0}...'.format(epoch + 1))\n",
    "                saver = tf.train.Saver()\n",
    "                saver.save(sess, self._saved_model_path)\n",
    "                print('Finished training, modeld saved.')\n",
    "\n",
    "                end = time.time()\n",
    "                print('Time elapsed: {0:.2f}s.'.format(end - start))\n",
    "\n",
    "    def predict(self, data, layer_name='prediction'):\n",
    "        with self._tf_graph.as_default():\n",
    "            with tf.Session(graph=self._tf_graph) as sess:\n",
    "                saver = tf.train.Saver()\n",
    "                saver.restore(sess, self._saved_model_path)\n",
    "                return sess.run(self._tf_dict[layer_name], feed_dict={self._tf_dict['X']: data})\n",
    "\n",
    "    @classmethod\n",
    "    def _get_tf_dict(cls, grah, img_size, num_categories, learning_rate, momentum):\n",
    "        with grah.as_default():\n",
    "            res = dict()\n",
    "            res['X'] = tf.placeholder(tf.float32, shape=(None, *img_size), name='input')\n",
    "            res['Y'] = tf.placeholder(tf.float32, shape=(None, num_categories), name='output')\n",
    "\n",
    "            res['filter_1'], res['conv_1'] = cls._filter_conv(res['X'], shape=(3, 3, img_size[-1], 64))\n",
    "            res['filter_2'], res['conv_2'] = cls._filter_conv(res['conv_1'], shape=(3, 3, 64, 64))\n",
    "            res['maxpool_3'] = cls._pool(res['conv_2'], 'MAX')\n",
    "\n",
    "            res['filter_4'], res['conv_4'] = cls._filter_conv(res['maxpool_3'], shape=(3, 3, 64, 128))\n",
    "            res['filter_5'], res['conv_5'] = cls._filter_conv(res['conv_4'], shape=(3, 3, 128, 128))\n",
    "            res['maxpool_6'] = cls._pool(res['conv_5'], 'MAX')\n",
    "\n",
    "            res['filter_7'], res['conv_7'] = cls._filter_conv(res['maxpool_6'], shape=(3, 3, 128, 256))\n",
    "            res['filter_8'], res['conv_8'] = cls._filter_conv(res['conv_7'], shape=(3, 3, 256, 256))\n",
    "            res['filter_9'], res['conv_9'] = cls._filter_conv(res['conv_8'], shape=(3, 3, 256, 256))\n",
    "            res['maxpool_10'] = cls._pool(res['conv_9'], 'MAX')\n",
    "\n",
    "            res['filter_11'], res['conv_11'] = cls._filter_conv(res['maxpool_10'], shape=(3, 3, 256, 512))\n",
    "            res['filter_12'], res['conv_12'] = cls._filter_conv(res['conv_11'], shape=(3, 3, 512, 512))\n",
    "            res['filter_13'], res['conv_13'] = cls._filter_conv(res['conv_12'], shape=(3, 3, 512, 512))\n",
    "            res['maxpool_14'] = cls._pool(res['conv_13'], 'MAX')\n",
    "\n",
    "            res['filter_15'], res['conv_15'] = cls._filter_conv(res['maxpool_14'], shape=(3, 3, 512, 512))\n",
    "            res['filter_16'], res['conv_16'] = cls._filter_conv(res['conv_15'], shape=(3, 3, 512, 512))\n",
    "            res['filter_17'], res['conv_17'] = cls._filter_conv(res['conv_16'], shape=(3, 3, 512, 512))\n",
    "            res['maxpool_18'] = cls._pool(res['conv_17'], 'MAX')\n",
    "\n",
    "#             unfold_shape = [512] if img_size[-1] == 1 else [7 * 7 * 512] # TODO: a hack\n",
    "            res['fc_19'] = tf.layers.Flatten()(res['maxpool_18'])\n",
    "            res['fc_20'] = tf.layers.dense(inputs=res['maxpool_18'], units=4096, activation=tf.nn.relu, trainable=True)\n",
    "            res['fc_21'] = tf.layers.dense(inputs=res['fc_20'], units=4096, activation=tf.nn.relu, trainable=True)\n",
    "            res['fc_22'] = tf.layers.dense(inputs=res['fc_21'], units=num_categories, activation=tf.nn.relu, trainable=True)\n",
    "\n",
    "            res['cost'] = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                labels=res['Y'],\n",
    "                logits=res['fc_22']\n",
    "            ))\n",
    "            res['prediction'] = tf.argmax(tf.nn.softmax(res['fc_22'], axis=-1), axis=-1)\n",
    "            res['optimizer'] = tf.train.AdamOptimizer(\n",
    "                learning_rate=learning_rate,\n",
    "                beta1=momentum\n",
    "            ).minimize(res['cost'])\n",
    "\n",
    "            return res\n",
    "\n",
    "    @classmethod\n",
    "    def _filter_conv(cls, input_value, shape, strides=(1, 1, 1, 1), padding='SAME', dtype=tf.float32):\n",
    "        res_filter = tf.Variable(tf.random_normal(shape), dtype=tf.float32, trainable=True)\n",
    "        res_conv = tf.nn.conv2d(input=input_value, filter=res_filter, strides=strides, padding=padding)\n",
    "        res_relu = tf.nn.relu(res_conv)\n",
    "        return res_filter, res_relu\n",
    "    \n",
    "    @classmethod\n",
    "    def _pool(cls, input_value, pool_style, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding='SAME'):\n",
    "        res_func = tf.nn.max_pool if pool_style == 'MAX' else tf.nn.avg_pool\n",
    "        return res_func(value=input_value, ksize=ksize, strides=strides, padding=padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Get MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-478afc6797d1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/mnist\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(\n",
    "    img_size=mnist.train.images.shape[1:],\n",
    "    num_categories=10,\n",
    "    learning_rate=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training...\n",
      "Finished epoch 100...\n",
      "Finished epoch 200...\n",
      "Finished epoch 300...\n",
      "Finished epoch 400...\n",
      "Finished epoch 500...\n",
      "Finished epoch 600...\n",
      "Finished epoch 700...\n",
      "Finished epoch 800...\n",
      "Finished epoch 900...\n",
      "Finished epoch 1000...\n",
      "Finished training, modeld saved.\n",
      "Time elapsed: 113.21s.\n"
     ]
    }
   ],
   "source": [
    "model.train(mnist, batch_size=256, num_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22f18f56940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_graph(model._train_loss, model._dev_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\SHUYAN~1\\AppData\\Local\\Temp\\tmp_hpj2whr\\model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]],\n",
       "\n",
       "       [[0]]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(mnist.test.images[:10], 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(mnist.test.labels[:10], axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
